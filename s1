import numpy as np
import cv2
from darkflow.net.build import TFNet
import matplotlib.pyplot as plt

%config InlineBackend.figure_format = 'svg'

# define the model options and run

options = {
    'model': 'cfg/yolo.cfg',
    'load': 'bin/yolo.weights',
    'threshold': 0.3,
    'gpu': 1.0
}

tfnet = TFNet(options)

cap = cv2.VideoCapture(0)

# Define the codec and create VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))

currentFrame = 0
while(True):
    # Capture frame-by-frame
    ret, frame = cap.read()
    
    # read the color image and covert to RGB

   img = cv2.imread(frame, cv2.IMREAD_COLOR)
   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

   # use YOLO to predict the image
   result = tfnet.return_predict(img)

  img.shape
  
  # pull out some info from the results

  tl = (result[0]['topleft']['x'], result[0]['topleft']['y'])
  br = (result[0]['bottomright']['x'], result[0]['bottomright']['y'])
  label = result[0]['label']


  # add the box and label and display it
  img = cv2.rectangle(img, tl, br, (0, 255, 0), 7)
  img = cv2.putText(img, label, tl, cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2)

 # Saves image of the current frame in jpg file
    name = './data/frame' + str(currentFrame) + '.jpg'
    print ('Creating...' + name)
    cv2.imwrite(name, img)

    # To stop duplicate images
    currentFrame += 1
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
    else:
        break

# Release everything if job is finished
cap.release()
cv2.destroyAllWindows()
